{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcNGJW87yHRW"
   },
   "outputs": [],
   "source": [
    "# ML_in_Finance-Deep-Learning-Interpretability\n",
    "# Author: Matthew Dixon\n",
    "# Version: 1.0 (08.09.2019)\n",
    "# License: MIT\n",
    "# Email: matthew.dixon@iit.edu\n",
    "# Notes: tested on Mac OS X with Python 3.6 and Tensorflow 1.3.0\n",
    "# Citation: Please cite the following reference if this notebook is used for research purposes:\n",
    "# Bilokon P., Dixon M.F. and I. Halperin, Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a3mMNZajyHRa",
    "outputId": "edb1c34b-1dfc-462b-bfc0-52957f785a44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as tds\n",
    "from statsmodels.api import add_constant\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sgs5P1QnyHRj"
   },
   "source": [
    "# Simple Data Generation Process (DGP)\n",
    "\n",
    "$Y=X_1+X_2 + X_1X_2+\\epsilon, ~X_1, X_2 \\sim N(0,1,), \\epsilon \\sim N(0,\\sigma_n^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvAYY7WOyHRk"
   },
   "outputs": [],
   "source": [
    "M = 5000\n",
    "np.random.seed(7)\n",
    "X = np.zeros(shape=(M,2))\n",
    "sigma_n = 0.01\n",
    "X[:int(M/2),0]= np.random.randn(int(M/2))\n",
    "X[:int(M/2),1]= np.random.randn(int(M/2))\n",
    "\n",
    "X[int(M/2):,0]= -X[:int(M/2),0]\n",
    "X[int(M/2):,1]= -X[:int(M/2),1]\n",
    "\n",
    "eps= np.random.randn(M)\n",
    "Y= 1.0*X[:,0] + 1.0*X[:,1] + 1.0*X[:,0]*X[:,1] + sigma_n*eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUcXdnjvyHRm"
   },
   "source": [
    "# Use OLS to fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rL-km9xSyHRn"
   },
   "outputs": [],
   "source": [
    "ols_results = sm.OLS(Y, sm.add_constant(X)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiO-mgbbyHRp"
   },
   "outputs": [],
   "source": [
    "y_ols=ols_results.predict(sm.add_constant(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "q9j5CY92yHRr",
    "outputId": "4d8d9d4d-33a2-4bca-fa09-ec3a488a31ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.669</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.669</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5052.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 30 Sep 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>04:11:07</td>     <th>  Log-Likelihood:    </th> <td> -7103.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>1.421e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4997</td>      <th>  BIC:               </th> <td>1.423e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0243</td> <td>    0.014</td> <td>    1.713</td> <td> 0.087</td> <td>   -0.004</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.9999</td> <td>    0.014</td> <td>   70.236</td> <td> 0.000</td> <td>    0.972</td> <td>    1.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0000</td> <td>    0.014</td> <td>   70.164</td> <td> 0.000</td> <td>    0.972</td> <td>    1.028</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>846.889</td> <th>  Durbin-Watson:     </th> <td>   2.024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>16614.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.168</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.924</td>  <th>  Cond. No.          </th> <td>    1.02</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.669\n",
       "Model:                            OLS   Adj. R-squared:                  0.669\n",
       "Method:                 Least Squares   F-statistic:                     5052.\n",
       "Date:                Mon, 30 Sep 2019   Prob (F-statistic):               0.00\n",
       "Time:                        04:11:07   Log-Likelihood:                -7103.5\n",
       "No. Observations:                5000   AIC:                         1.421e+04\n",
       "Df Residuals:                    4997   BIC:                         1.423e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0243      0.014      1.713      0.087      -0.004       0.052\n",
       "x1             0.9999      0.014     70.236      0.000       0.972       1.028\n",
       "x2             1.0000      0.014     70.164      0.000       0.972       1.028\n",
       "==============================================================================\n",
       "Omnibus:                      846.889   Durbin-Watson:                   2.024\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16614.377\n",
       "Skew:                           0.168   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.924   Cond. No.                         1.02\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yviFcbA7yHRu"
   },
   "source": [
    "# Compare with a ffwd neural network with no hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgvCP9duyHRy"
   },
   "outputs": [],
   "source": [
    "def linear_NN0_model(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=2, kernel_initializer='normal')) #, activation='None'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OdPL_ETyHR2"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyER55lFyHR4"
   },
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN0_model, epochs=40, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KmuDbu_8yHR7",
    "outputId": "af5a09fb-076f-48f2-edc0-d27a15cbc270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/40\n",
      "5000/5000 [==============================] - 1s 195us/step - loss: 2.1871 - mean_absolute_error: 1.0363 - mean_squared_error: 2.1871\n",
      "Epoch 2/40\n",
      "5000/5000 [==============================] - 0s 83us/step - loss: 1.4522 - mean_absolute_error: 0.7912 - mean_squared_error: 1.4522\n",
      "Epoch 3/40\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 1.1473 - mean_absolute_error: 0.6760 - mean_squared_error: 1.1473\n",
      "Epoch 4/40\n",
      "5000/5000 [==============================] - 0s 84us/step - loss: 1.0432 - mean_absolute_error: 0.6392 - mean_squared_error: 1.0432\n",
      "Epoch 5/40\n",
      "5000/5000 [==============================] - 0s 81us/step - loss: 1.0133 - mean_absolute_error: 0.6288 - mean_squared_error: 1.0133\n",
      "Epoch 6/40\n",
      "5000/5000 [==============================] - 0s 84us/step - loss: 1.0068 - mean_absolute_error: 0.6265 - mean_squared_error: 1.0068\n",
      "Epoch 7/40\n",
      "5000/5000 [==============================] - 0s 80us/step - loss: 1.0052 - mean_absolute_error: 0.6260 - mean_squared_error: 1.0052\n",
      "Epoch 8/40\n",
      "5000/5000 [==============================] - 0s 81us/step - loss: 1.0048 - mean_absolute_error: 0.6261 - mean_squared_error: 1.0048\n",
      "Epoch 9/40\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 1.0047 - mean_absolute_error: 0.6259 - mean_squared_error: 1.0047\n",
      "Epoch 10/40\n",
      "5000/5000 [==============================] - 0s 84us/step - loss: 1.0050 - mean_absolute_error: 0.6264 - mean_squared_error: 1.0050\n",
      "Epoch 11/40\n",
      "5000/5000 [==============================] - 0s 82us/step - loss: 1.0047 - mean_absolute_error: 0.6258 - mean_squared_error: 1.0047\n",
      "Epoch 12/40\n",
      "5000/5000 [==============================] - 0s 84us/step - loss: 1.0046 - mean_absolute_error: 0.6258 - mean_squared_error: 1.0046\n",
      "Epoch 13/40\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 1.0045 - mean_absolute_error: 0.6260 - mean_squared_error: 1.0045\n",
      "Epoch 14/40\n",
      "5000/5000 [==============================] - 0s 83us/step - loss: 1.0048 - mean_absolute_error: 0.6259 - mean_squared_error: 1.0048\n",
      "Epoch 15/40\n",
      "5000/5000 [==============================] - 0s 83us/step - loss: 1.0048 - mean_absolute_error: 0.6263 - mean_squared_error: 1.0048\n",
      "Epoch 16/40\n",
      "5000/5000 [==============================] - 0s 84us/step - loss: 1.0047 - mean_absolute_error: 0.6260 - mean_squared_error: 1.0047\n",
      "Epoch 17/40\n",
      "5000/5000 [==============================] - 0s 94us/step - loss: 1.0047 - mean_absolute_error: 0.6260 - mean_squared_error: 1.0047\n",
      "Epoch 18/40\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 1.0046 - mean_absolute_error: 0.6259 - mean_squared_error: 1.0046\n",
      "Epoch 19/40\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 1.0048 - mean_absolute_error: 0.6261 - mean_squared_error: 1.0048\n",
      "Epoch 20/40\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 1.0048 - mean_absolute_error: 0.6261 - mean_squared_error: 1.0048\n",
      "Epoch 21/40\n",
      "5000/5000 [==============================] - 0s 90us/step - loss: 1.0048 - mean_absolute_error: 0.6258 - mean_squared_error: 1.0048\n",
      "Epoch 22/40\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 1.0048 - mean_absolute_error: 0.6262 - mean_squared_error: 1.0048\n",
      "Epoch 23/40\n",
      "5000/5000 [==============================] - 0s 81us/step - loss: 1.0049 - mean_absolute_error: 0.6260 - mean_squared_error: 1.0049\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8d0e324e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-9RjEXSyHR9"
   },
   "source": [
    "## Check that the weights are close to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Y5Q9Va1oyHR-",
    "outputId": "40587576-9d43-4eff-b3e3-2c41d7aa8503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.99630827],\n",
       "        [0.99237144]], dtype=float32), array([0.02239072], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obRMud0ryHSA"
   },
   "source": [
    "# Compare with a FFW Neural Network with one hidden layer (unactivated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srwXD-FwyHSC"
   },
   "outputs": [],
   "source": [
    "n = 10 # number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QK2tTE6yHSF"
   },
   "outputs": [],
   "source": [
    "def linear_NN1_model(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim=2, kernel_initializer='normal')) \n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84yvSspzyHSI"
   },
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN1_model, epochs=50, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "QBI2ly--yHSL",
    "outputId": "dcf2392e-6864-4742-c051-402ae19fcf81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 1s 120us/step - loss: 1.6925 - mean_absolute_error: 0.8499 - mean_squared_error: 1.6925\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 1.0064 - mean_absolute_error: 0.6269 - mean_squared_error: 1.0064\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 1.0069 - mean_absolute_error: 0.6264 - mean_squared_error: 1.0069\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 1s 101us/step - loss: 1.0101 - mean_absolute_error: 0.6284 - mean_squared_error: 1.0101\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 1.0089 - mean_absolute_error: 0.6268 - mean_squared_error: 1.0089\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 1.0082 - mean_absolute_error: 0.6265 - mean_squared_error: 1.0082\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 1.0069 - mean_absolute_error: 0.6275 - mean_squared_error: 1.0069\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 1.0089 - mean_absolute_error: 0.6271 - mean_squared_error: 1.0089\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 0s 95us/step - loss: 1.0096 - mean_absolute_error: 0.6282 - mean_squared_error: 1.0096\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 1.0075 - mean_absolute_error: 0.6270 - mean_squared_error: 1.0075\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 1.0097 - mean_absolute_error: 0.6284 - mean_squared_error: 1.0097\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 1.0080 - mean_absolute_error: 0.6274 - mean_squared_error: 1.0080\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8d3ee8d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "l_I09KE-yHSN",
    "outputId": "40483692-9542-4785-c4d8-353648677579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38218114  0.30856702 -0.2751086   0.37145826  0.33706802 -0.30469328\n",
      "  -0.26317063 -0.3033631  -0.29963627  0.28915673]\n",
      " [-0.2602884   0.2979248  -0.3484488   0.25811747  0.20207882 -0.35329625\n",
      "  -0.3216379  -0.25279254 -0.31120202  0.31780183]] [[-0.28753257]\n",
      " [ 0.30950925]\n",
      " [-0.3259624 ]\n",
      " [ 0.30738404]\n",
      " [ 0.31808805]\n",
      " [-0.320297  ]\n",
      " [-0.29133117]\n",
      " [-0.36196095]\n",
      " [-0.33513585]\n",
      " [ 0.3447407 ]]\n"
     ]
    }
   ],
   "source": [
    "W1=lm.model.get_weights()[0]\n",
    "b1=lm.model.get_weights()[1]\n",
    "W2=lm.model.get_weights()[2]\n",
    "b2=lm.model.get_weights()[3]\n",
    "print(W1, W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SljFwa5AyHSP"
   },
   "source": [
    "## Check that the coefficients are close to one and the intercept is close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OktfkdzJyHSQ"
   },
   "outputs": [],
   "source": [
    "beta_0=np.dot(np.transpose(W2), b1) + b2\n",
    "beta_1=np.dot(np.transpose(W2), W1[0])\n",
    "beta_2=np.dot(np.transpose(W2), W1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lRXWawi-yHSS",
    "outputId": "afe03eea-c3fc-446d-ee12-d539875ba2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03099869] [1.0006373] [0.9364712]\n"
     ]
    }
   ],
   "source": [
    "print(beta_0,beta_1,beta_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbGdm6-9yHSV"
   },
   "source": [
    "# Compare with a FFW Neural Network with one hidden layer (tanh activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezbYEyNkyHSX"
   },
   "outputs": [],
   "source": [
    "# number of hidden neurons\n",
    "n=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auDhiZFzyHSb"
   },
   "outputs": [],
   "source": [
    "# with non-linear activation\n",
    "def linear_NN1_model_act(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim=2, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer='normal')) \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3LA_IQgyHSe"
   },
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN1_model_act, epochs=100, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QvNfri4MyHSg",
    "outputId": "d72c4583-7bed-4160-f8ab-e4f6f996fe7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 1.1540 - mean_absolute_error: 0.6732 - mean_squared_error: 1.1540\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 1s 115us/step - loss: 1.0159 - mean_absolute_error: 0.6295 - mean_squared_error: 1.0159\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 1.0016 - mean_absolute_error: 0.6252 - mean_squared_error: 1.0016\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.9872 - mean_absolute_error: 0.6202 - mean_squared_error: 0.9872\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.9205 - mean_absolute_error: 0.5974 - mean_squared_error: 0.9205\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.7582 - mean_absolute_error: 0.5275 - mean_squared_error: 0.7582\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.4918 - mean_absolute_error: 0.3931 - mean_squared_error: 0.4918\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.2613 - mean_absolute_error: 0.2283 - mean_squared_error: 0.2613\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.1452 - mean_absolute_error: 0.1491 - mean_squared_error: 0.1452\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.0996 - mean_absolute_error: 0.1331 - mean_squared_error: 0.0996\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0760 - mean_absolute_error: 0.1220 - mean_squared_error: 0.0760\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0633 - mean_absolute_error: 0.1142 - mean_squared_error: 0.0633\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0529 - mean_absolute_error: 0.1040 - mean_squared_error: 0.0529\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0459 - mean_absolute_error: 0.1026 - mean_squared_error: 0.0459\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0401 - mean_absolute_error: 0.0921 - mean_squared_error: 0.0401\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0353 - mean_absolute_error: 0.0915 - mean_squared_error: 0.0353\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0311 - mean_absolute_error: 0.0837 - mean_squared_error: 0.0311\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.0278 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0278\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0260 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0260\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0228 - mean_absolute_error: 0.0711 - mean_squared_error: 0.0228\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0233 - mean_absolute_error: 0.0762 - mean_squared_error: 0.0233\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0205 - mean_absolute_error: 0.0684 - mean_squared_error: 0.0205\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0190 - mean_absolute_error: 0.0669 - mean_squared_error: 0.0190\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0176 - mean_absolute_error: 0.0649 - mean_squared_error: 0.0176\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0162 - mean_absolute_error: 0.0618 - mean_squared_error: 0.0162\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0154 - mean_absolute_error: 0.0602 - mean_squared_error: 0.0154\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 1s 113us/step - loss: 0.0143 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0143\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 1s 112us/step - loss: 0.0135 - mean_absolute_error: 0.0561 - mean_squared_error: 0.0135\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0127 - mean_absolute_error: 0.0562 - mean_squared_error: 0.0127\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0120 - mean_absolute_error: 0.0521 - mean_squared_error: 0.0120\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 1s 113us/step - loss: 0.0108 - mean_absolute_error: 0.0501 - mean_squared_error: 0.0108\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 1s 113us/step - loss: 0.0101 - mean_absolute_error: 0.0479 - mean_squared_error: 0.0101\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0102 - mean_absolute_error: 0.0480 - mean_squared_error: 0.0102\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 1s 112us/step - loss: 0.0094 - mean_absolute_error: 0.0481 - mean_squared_error: 0.0094\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.0081 - mean_absolute_error: 0.0411 - mean_squared_error: 0.0081\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0074 - mean_absolute_error: 0.0395 - mean_squared_error: 0.0074\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.0069 - mean_absolute_error: 0.0365 - mean_squared_error: 0.0069\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0068 - mean_absolute_error: 0.0367 - mean_squared_error: 0.0068\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0060 - mean_absolute_error: 0.0331 - mean_squared_error: 0.0060\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0055 - mean_absolute_error: 0.0328 - mean_squared_error: 0.0055\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.0049 - mean_absolute_error: 0.0298 - mean_squared_error: 0.0049\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0050 - mean_absolute_error: 0.0327 - mean_squared_error: 0.0050\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0047 - mean_absolute_error: 0.0314 - mean_squared_error: 0.0047\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0048 - mean_absolute_error: 0.0348 - mean_squared_error: 0.0048\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0044 - mean_absolute_error: 0.0301 - mean_squared_error: 0.0044\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.0043 - mean_absolute_error: 0.0310 - mean_squared_error: 0.0043\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0038 - mean_absolute_error: 0.0300 - mean_squared_error: 0.0038\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0038 - mean_absolute_error: 0.0294 - mean_squared_error: 0.0038\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0037 - mean_absolute_error: 0.0300 - mean_squared_error: 0.0037\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0035 - mean_absolute_error: 0.0278 - mean_squared_error: 0.0035\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0037 - mean_absolute_error: 0.0282 - mean_squared_error: 0.0037\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 1s 122us/step - loss: 0.0034 - mean_absolute_error: 0.0291 - mean_squared_error: 0.0034\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0033 - mean_absolute_error: 0.0275 - mean_squared_error: 0.0033\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0034 - mean_absolute_error: 0.0286 - mean_squared_error: 0.0034\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0024 - mean_absolute_error: 0.0218 - mean_squared_error: 0.0024\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0031 - mean_absolute_error: 0.0282 - mean_squared_error: 0.0031\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0028 - mean_absolute_error: 0.0272 - mean_squared_error: 0.0028\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0026 - mean_absolute_error: 0.0254 - mean_squared_error: 0.0026\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0029 - mean_absolute_error: 0.0280 - mean_squared_error: 0.0029\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.0028 - mean_absolute_error: 0.0262 - mean_squared_error: 0.0028\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0028 - mean_absolute_error: 0.0257 - mean_squared_error: 0.0028\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0024 - mean_absolute_error: 0.0251 - mean_squared_error: 0.0024\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0022 - mean_absolute_error: 0.0225 - mean_squared_error: 0.0022\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0028 - mean_absolute_error: 0.0283 - mean_squared_error: 0.0028\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 1s 119us/step - loss: 0.0022 - mean_absolute_error: 0.0246 - mean_squared_error: 0.0022\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.0025 - mean_absolute_error: 0.0262 - mean_squared_error: 0.0025\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.0021 - mean_absolute_error: 0.0234 - mean_squared_error: 0.0021\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 1s 118us/step - loss: 0.0022 - mean_absolute_error: 0.0236 - mean_squared_error: 0.0022\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0022 - mean_absolute_error: 0.0235 - mean_squared_error: 0.0022\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0019 - mean_absolute_error: 0.0219 - mean_squared_error: 0.0019\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 1s 115us/step - loss: 0.0022 - mean_absolute_error: 0.0249 - mean_squared_error: 0.0022\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.0028 - mean_absolute_error: 0.0244 - mean_squared_error: 0.0028\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.0017 - mean_absolute_error: 0.0220 - mean_squared_error: 0.0017\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0017 - mean_absolute_error: 0.0208 - mean_squared_error: 0.0017\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0018 - mean_absolute_error: 0.0237 - mean_squared_error: 0.0018\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.0018 - mean_absolute_error: 0.0213 - mean_squared_error: 0.0018\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0018 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0018\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0018 - mean_absolute_error: 0.0226 - mean_squared_error: 0.0018\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0017 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0017\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0015 - mean_absolute_error: 0.0196 - mean_squared_error: 0.0015\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 1s 118us/step - loss: 0.0017 - mean_absolute_error: 0.0220 - mean_squared_error: 0.0017\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0019 - mean_absolute_error: 0.0224 - mean_squared_error: 0.0019\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 1s 116us/step - loss: 0.0015 - mean_absolute_error: 0.0200 - mean_squared_error: 0.0015\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0014 - mean_absolute_error: 0.0185 - mean_squared_error: 0.0014  \n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0017 - mean_absolute_error: 0.0230 - mean_squared_error: 0.0017\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0013 - mean_absolute_error: 0.0192 - mean_squared_error: 0.0013\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0013 - mean_absolute_error: 0.0179 - mean_squared_error: 0.0013\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0015 - mean_absolute_error: 0.0211 - mean_squared_error: 0.0015\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.0013 - mean_absolute_error: 0.0190 - mean_squared_error: 0.0013\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0016 - mean_absolute_error: 0.0240 - mean_squared_error: 0.0016\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 1s 115us/step - loss: 0.0011 - mean_absolute_error: 0.0181 - mean_squared_error: 0.0011\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.0011 - mean_absolute_error: 0.0171 - mean_squared_error: 0.0011  \n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0013 - mean_absolute_error: 0.0199 - mean_squared_error: 0.0013\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0014 - mean_absolute_error: 0.0207 - mean_squared_error: 0.0014\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.0015 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0015\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.0012 - mean_absolute_error: 0.0191 - mean_squared_error: 0.0012\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.0011 - mean_absolute_error: 0.0185 - mean_squared_error: 0.0011\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.0011 - mean_absolute_error: 0.0164 - mean_squared_error: 0.0011  \n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.0012 - mean_absolute_error: 0.0202 - mean_squared_error: 0.0012\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.0013 - mean_absolute_error: 0.0204 - mean_squared_error: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8cb45c4a8>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7tsdno-yHSl"
   },
   "source": [
    "## Compute the sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geS5o6z0yHSm"
   },
   "outputs": [],
   "source": [
    "# Assume that the activation function is tanh\n",
    "def sensitivities(lm, X):\n",
    "    \n",
    "    W1=lm.model.get_weights()[0]\n",
    "    b1=lm.model.get_weights()[1]\n",
    "    W2=lm.model.get_weights()[2]\n",
    "    b2=lm.model.get_weights()[3]\n",
    "    \n",
    "    \n",
    "    M = np.shape(X)[0]\n",
    "    p = np.shape(X)[1]\n",
    "\n",
    "    beta=np.array([0]*M*(p+1), dtype='float32').reshape(M,p+1)\n",
    "    beta_interact=np.array([0]*M*p*p, dtype='float32').reshape(M,p,p)\n",
    "    \n",
    "    beta[:,0]= (np.dot(np.transpose(W2),np.tanh(b1)) + b2)[0] # intercept \\beta_0= F_{W,b}(0)\n",
    "    for i in range(M):\n",
    " \n",
    "      Z1 = np.tanh(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1)\n",
    "      #Z1 = np.maximum(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1,0) \n",
    "      \n",
    "      D = np.diag(1-Z1**2) \n",
    "      D_prime =np.diag(-2*Z1*(1-Z1**2))   # needed for interaction term     \n",
    "      #D = np.diag(np.sign(Z1))  \n",
    "        \n",
    "      for j in range(p):  \n",
    "          beta[i,j+1]=np.dot(np.transpose(W2),np.dot(D,W1[j]))\n",
    "          #interaction term \n",
    "          for k in range(p):\n",
    "            beta_interact[i,j,k]=np.dot(np.transpose(W2),np.dot(np.diag(W1[j]), np.dot(D_prime,W1[k])))  \n",
    "    \n",
    "            \n",
    "    return(beta, beta_interact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GN3w_ztGyHSr"
   },
   "outputs": [],
   "source": [
    "beta, beta_inter=sensitivities(lm, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sxRfJpEyHSu"
   },
   "source": [
    "## Check that the intercept is close to one and the coefficients are close to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EkYmEh2ByHSx",
    "outputId": "62679423-1544-41e7-a0d6-3a6d91b7242e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00380707  0.9939782   0.9854333 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(beta, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jix-ErNav2C6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cb2RJ76NyHS1",
    "outputId": "41c237f9-2caa-4eb5-b67c-083b5012b7a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.6111730e-08 9.9354202e-01 9.9351066e-01]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(beta, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "kll1Ku9yyHS4",
    "outputId": "3aa0d16b-2fbd-401b-b667-196305767e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.4412134e-03 9.9882346e-01]\n",
      " [9.9882346e-01 2.1300343e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(beta_inter, axis=0)) # off-diagonals are interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HY2aSf2ID1wC",
    "outputId": "4f008f79-b437-40cf-caf6-205ee1ac060e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05352347 0.0553919 ]\n",
      " [0.0553919  0.05925729]]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(beta_inter, axis=0)) # off-diagonals are interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHBBYAIKvIaJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deep_Learning_Interaction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

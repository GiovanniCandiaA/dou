{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXPONxBdvoVC"
   },
   "source": [
    "# Noah Grudowski\n",
    "## MATH 527 Homework 2\n",
    "### 9/25/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a_YDQVDGvl69",
    "outputId": "22e6b24b-0b0a-47df-ce7b-8559043155a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as tds\n",
    "from statsmodels.api import add_constant\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAzHvnyHvzUF"
   },
   "source": [
    "# Simple Data Generation Process (DGP)\n",
    "\n",
    "$Y=X_1+X_2 + \\epsilon, ~X_1, X_2, \\epsilon \\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86KnPsJGv1iD"
   },
   "outputs": [],
   "source": [
    "M = 5000 # Number of sample \n",
    "np.random.seed(7) # set the seed for reproducebility of results\n",
    "X = np.zeros(shape=(M,2))\n",
    "X[:int(M/2),0]= np.random.randn(int(M/2))\n",
    "X[:int(M/2),1]= np.random.randn(int(M/2))\n",
    "\n",
    "X[int(M/2):,0]= -X[:int(M/2),0]\n",
    "X[int(M/2):,1]= -X[:int(M/2),1]\n",
    "\n",
    "\n",
    "eps= np.random.randn(M)\n",
    "Y= 1.0*X[:,0] + 1.0*X[:,1] + eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8p8gx8iv44R"
   },
   "source": [
    "# Use a FFW Neural Network with One Hidden Layer (tanh Activated) to Fit the Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOkqx0Kqv4Ny"
   },
   "outputs": [],
   "source": [
    "# number of hidden neurons\n",
    "n=500\n",
    "\n",
    "#number of layers\n",
    "L=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kR8s0_7Ev_6_"
   },
   "outputs": [],
   "source": [
    "# with non-linear activation\n",
    "def linear_NN1_model_act(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    for i in range(L):\n",
    "      model.add(Dense(n, input_dim=2, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer='normal')) \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TmmpwBVwAN4"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPx1FLNGwBFD"
   },
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN1_model_act, epochs=100, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "8QXGKdIJwDJY",
    "outputId": "1758e18e-78ef-4149-9243-42541a1a72f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 2s 306us/step - loss: 1.0374 - mean_absolute_error: 0.8096 - mean_squared_error: 1.0374\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 1s 124us/step - loss: 0.9928 - mean_absolute_error: 0.7957 - mean_squared_error: 0.9928\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 1s 123us/step - loss: 0.9930 - mean_absolute_error: 0.7943 - mean_squared_error: 0.9930\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 1s 135us/step - loss: 0.9958 - mean_absolute_error: 0.7965 - mean_squared_error: 0.9958\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 1s 127us/step - loss: 0.9863 - mean_absolute_error: 0.7927 - mean_squared_error: 0.9863\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 1s 125us/step - loss: 0.9903 - mean_absolute_error: 0.7924 - mean_squared_error: 0.9903\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 1s 123us/step - loss: 0.9918 - mean_absolute_error: 0.7937 - mean_squared_error: 0.9918\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s 124us/step - loss: 0.9923 - mean_absolute_error: 0.7945 - mean_squared_error: 0.9923\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 1s 124us/step - loss: 0.9900 - mean_absolute_error: 0.7953 - mean_squared_error: 0.9900\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 1s 125us/step - loss: 0.9883 - mean_absolute_error: 0.7924 - mean_squared_error: 0.9883\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s 121us/step - loss: 0.9883 - mean_absolute_error: 0.7940 - mean_squared_error: 0.9883\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 1s 125us/step - loss: 0.9899 - mean_absolute_error: 0.7945 - mean_squared_error: 0.9899\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 1s 125us/step - loss: 0.9870 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9870\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s 124us/step - loss: 0.9912 - mean_absolute_error: 0.7953 - mean_squared_error: 0.9912\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s 126us/step - loss: 0.9915 - mean_absolute_error: 0.7946 - mean_squared_error: 0.9915\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2782970b8>"
      ]
     },
     "execution_count": 271,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXtrhOnUwUce"
   },
   "source": [
    "## Compute the sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oy-KDEZx5tBI"
   },
   "outputs": [],
   "source": [
    "#lm.model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-34qK_Z_yiG"
   },
   "outputs": [],
   "source": [
    "#Assume the activation function is tanh\n",
    "def sensitivities(lm,X):\n",
    "  \n",
    "  M = np.shape(X)[0]\n",
    "  p = np.shape(X)[1]\n",
    "  \n",
    "  W = []\n",
    "  b = []\n",
    "  z = []\n",
    "  \n",
    "  for i in range(0,L+1):\n",
    "    W_ = lm.model.get_weights()[2*i]\n",
    "    b_ = lm.model.get_weights()[2*i+1]\n",
    "    W.append(W_)\n",
    "    b.append(b_)\n",
    "    \n",
    "    if i==0:\n",
    "      for k in range(M):\n",
    "        z.append(np.tanh(np.dot(np.transpose(W_),np.transpose(X[k,])) + b_))\n",
    "    else:\n",
    "      for k in range(M):\n",
    "        z.append(np.tanh(np.dot(np.transpose(W_),np.transpose(z[-(1+k)])) + b_))\n",
    "     \n",
    "  betas = np.array([0]*M*(p+1), dtype = 'float32').reshape(M,p+1)\n",
    "  beta = np.transpose(W[-1])\n",
    "  \n",
    "  for k in range(2,M):\n",
    "    for l in range(1,L):\n",
    "      beta = np.transpose(W[-1])\n",
    "      D = np.diag(1-z[(-(l+1)*M-k)]**2)\n",
    "      beta = np.dot(beta,np.dot(D,np.transpose(W[-(l+1)])))\n",
    "         \n",
    "    D = np.diag(1-z[-L*M-k]**2)\n",
    "    \n",
    "    betas[k,1:]=np.dot(beta,np.dot(D, np.transpose(W[-(L+1)])))\n",
    "  \n",
    "  return(betas)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZbZ_cu2wa0k"
   },
   "outputs": [],
   "source": [
    "beta=sensitivities(lm, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHJDNG-s_v_k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5i-_VngwhII"
   },
   "source": [
    "## Check: Intercept is close to zero and the coefficients are close to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-DeCxmg9whgJ",
    "outputId": "c7b95604-8114-49ab-d045-c4d6c7df0996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        1.016831  0.9878523]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(beta, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tKqIIdrpwh3l",
    "outputId": "dda21eb7-0e8e-4258-e1d7-831fe2371016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.03252291 0.03242064]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(beta, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDLzGStNwigV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Noah Grudowski MATH 527 Homework 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
